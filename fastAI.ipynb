{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ml/anaconda35/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_path=\"data/tgs/\"#\"../input/tgs-salt-identification-challenge/\"\n",
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(basic_path+\"train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(basic_path+\"depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4071bc9629714cc09f55d0938ff42a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ml/anaconda35/lib/python3.6/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(basic_path+\"TRN_images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685b4621994b4fba801c892a2c10fd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ml/anaconda35/lib/python3.6/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(basic_path+\"TRN_masks/{}.png\".format(idx), grayscale=True)) / 255 \n",
    "                     for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 21):\n",
    "        if val * 20 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.12, stratify=train_df.coverage_class, random_state= 1224)\n",
    "\n",
    "import gc\n",
    "del x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['99b602dde4', '07bb074759', '9c4468a160', 'fc87224914',\n",
       "       '40a7f422e2'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ids_valid.shape)\n",
    "ids_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from fastai.models.resnet import vgg_resnet50\n",
    "from fastai.models.senet import *\n",
    "from skimage.transform import resize\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold , KFold\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from pycocotools import mask as cocomask\n",
    "from utils import my_eval,intersection_over_union_thresholds,RLenc\n",
    "from lovasz_losses import lovasz_hinge\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "#True 注意GPU是set True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = Path('data/tgs/')\n",
    "TRN_MASKS = 'trn_masks'\n",
    "TRN_IMG = 'trn_images'\n",
    "TRN_MSK = 'trn_masks'\n",
    "TST_IMG = 'tst_images'\n",
    "trn = pd.read_csv(PATH/'train.csv')\n",
    "dpth = pd.read_csv(PATH/'depths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DepthDataset(Dataset):\n",
    "    def __init__(self,ds,dpth_dict):\n",
    "        self.dpth = dpth_dict\n",
    "        self.ds = ds\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        val = self.ds[i]\n",
    "        return val[0],self.dpth[self.ds.fnames[i].split('/')[1][:-4]],val[1]\n",
    "    \n",
    "class MatchedFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform, path):\n",
    "        self.y=y\n",
    "        assert(len(fnames)==len(y))\n",
    "        super().__init__(fnames, transform, path)\n",
    "        \n",
    "    def get_x(self, i): \n",
    "        return open_image(os.path.join(self.path, self.fnames[i]))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        return open_image(os.path.join(str(self.path), str(self.y[i])))\n",
    "\n",
    "    def get_c(self): return 0\n",
    "    \n",
    "class TestFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform,flip, path):\n",
    "        self.y=y\n",
    "        self.flip = flip\n",
    "        super().__init__(fnames, transform, path)\n",
    "        \n",
    "    def get_x(self, i): \n",
    "        im = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        return np.fliplr(im) if self.flip else im\n",
    "        \n",
    "    def get_y(self, i):\n",
    "        im = open_image(os.path.join(str(self.path), str(self.y[i])))\n",
    "        return np.fliplr(im) if self.flip else im\n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_names = np.array([f'{TRN_IMG}/{o.name}' for o in (PATH/TRN_MASKS).iterdir()])\n",
    "y_names = np.array([f'{TRN_MASKS}/{o.name}' for o in (PATH/TRN_MASKS).iterdir()])\n",
    "tst_x = np.array([f'{TST_IMG}/{o.name}' for o in (PATH/TST_IMG).iterdir()])\n",
    "f_name = [o.split('/')[-1] for o in x_names]\n",
    "\n",
    "c = dpth.set_index('id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_folds=[]\n",
    "val_folds=[]\n",
    "\n",
    "train_fold=[]\n",
    "val_fold=[]\n",
    "for img_name in ids_train:\n",
    "    train_fold.append(img_name+\".png\")\n",
    "    train_fold.append(img_name+\"_Crop.png\")\n",
    "#     train_fold.append(img_name+\"_aug2.png\")\n",
    "train_folds.append(train_fold)\n",
    "\n",
    "for img_name in ids_valid:\n",
    "    val_fold.append(img_name+\".png\")\n",
    "val_folds.append(val_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "480\n",
      "1\n",
      "7040\n"
     ]
    }
   ],
   "source": [
    "print(len(val_folds))\n",
    "print(len(val_folds[0]))  # 8折交叉验证  只存放了图片名字 跑前5折即可\n",
    "\n",
    "print(len(train_folds))\n",
    "print(len(train_folds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32560\n"
     ]
    }
   ],
   "source": [
    "dpth_dict = c['z'].to_dict()\n",
    "for item in ids_train:\n",
    "    dpth_dict[item+\"_aug1\"]=dpth_dict[item]\n",
    "    dpth_dict[item+\"_aug2\"]=dpth_dict[item]\n",
    "    dpth_dict[item+\"_Crop\"]=dpth_dict[item]\n",
    "    \n",
    "print(len(dpth_dict.items())) # 22000+3520*2 \n",
    "\n",
    "kf = 8\n",
    "# kfold = KFold(n_splits=kf, shuffle=True, random_state=42) # 设置shuffle=True和random_state=整数，发现每次运行的结果都相同\n",
    "\n",
    "# train_folds = []\n",
    "# val_folds = []\n",
    "# for idxs in kfold.split(f_name):\n",
    "#     train_folds.append([f_name[idx] for idx in idxs[0]])\n",
    "#     val_folds.append([f_name[idx] for idx in idxs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class SaveFeatures():\n",
    "#     features=None\n",
    "#     def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "#     def hook_fn(self, module, input, output): self.features = output\n",
    "#     def remove(self): self.hook.remove()\n",
    "    \n",
    "# class scSEModule(nn.Module):\n",
    "#     def __init__(self, ch, re=4):\n",
    "#         super().__init__()\n",
    "#         self.cSE = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "#                                  nn.Conv2d(ch,ch//re,1),\n",
    "#                                  nn.ReLU(inplace=True),\n",
    "#                                  nn.Conv2d(ch//re,ch,1),\n",
    "#                                  nn.Sigmoid()\n",
    "#                                )\n",
    "#         self.sSE = nn.Sequential(nn.Conv2d(ch,ch,1),\n",
    "#                                  nn.Sigmoid())\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return x * self.cSE(x) + x * self.sSE(x)\n",
    "    \n",
    "# # decoder block 设计太简单，可以增强一些\n",
    "# class UnetBlock(nn.Module):\n",
    "#     def __init__(self, up_in, x_in, n_out,dropout_ratio=0):\n",
    "#         super().__init__()\n",
    "#         up_out = x_out = n_out//2\n",
    "#         self.x_conv  = nn.Conv2d(x_in,  x_out,  1) # x_in 经过一个1x1卷积 调节通道数对齐\n",
    "#         self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "#         self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "#         self.scSE= scSEModule(n_out,re=2)\n",
    "        \n",
    "#         self.dropout_ratio=dropout_ratio\n",
    "        \n",
    "#     def forward(self, up_p, x_p):\n",
    "#         up_p = self.tr_conv(up_p)\n",
    "#         x_p = self.x_conv(x_p)\n",
    "#         cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "#         cat_p= self.bn(F.relu(cat_p))\n",
    "#         out=F.dropout2d(self.scSE(cat_p),self.dropout_ratio,training=self.training)\n",
    "#         return out\n",
    "    \n",
    "# class Unet34(nn.Module):\n",
    "#     def __init__(self, rn):\n",
    "#         super().__init__()\n",
    "#         self.rn = rn\n",
    "#         self.sfs = [SaveFeatures(rn[i]) for i in [3,6,8,10]] #提取 2 4 5 6的输出features \n",
    "        \n",
    "#         self.encoder_enhance=nn.Sequential( scSEModule(512,re=4),\n",
    "#                                             nn.Dropout2d(p=0.1))\n",
    "        \n",
    "#         self.middle=nn.Conv2d(512,512,1,stride=1)\n",
    "        \n",
    "#         self.up1 = UnetBlock(512,256,128,dropout_ratio=0.2)\n",
    "#         self.up2 = UnetBlock(128,128,128,dropout_ratio=0.2)\n",
    "#         self.up3 = UnetBlock(128,64,128, dropout_ratio=0.2)\n",
    "#         self.up4 = UnetBlock(128,64,128, dropout_ratio=0.2)\n",
    "#         self.up5 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        \n",
    "#         self.final=nn.Conv2d(64,1,1)\n",
    "        \n",
    "#     def forward(self,img,depth):\n",
    "#         #print(\"model.trainging:\",self.training)\n",
    "#         # encoder \n",
    "#         x = F.relu(self.rn(img))\n",
    "#         x = self.encoder_enhance(x)\n",
    "#         Summary=False\n",
    "#         if Summary:\n",
    "#             print(\"encoder out:\",x.shape)\n",
    "        \n",
    "#         x= self.middle(x)\n",
    "        \n",
    "#         x = self.up1(x, self.sfs[3].features) # 这样似乎就断开了直接的改变loss\n",
    "#         if Summary:\n",
    "#             print(\"decoder up1:\",x.shape)\n",
    "            \n",
    "#         x = self.up2(x, self.sfs[2].features)\n",
    "#         if Summary:\n",
    "#             print(\"decoder up2:\",x.shape)\n",
    "            \n",
    "#         x = self.up3(x, self.sfs[1].features)\n",
    "#         if Summary:\n",
    "#             print(\"decoder up3:\",x.shape)\n",
    "            \n",
    "#         x = self.up4(x, self.sfs[0].features)\n",
    "#         if Summary:\n",
    "#             print(\"decoder up4:\",x.shape)\n",
    "            \n",
    "#         x = self.up5(x)\n",
    "#         if Summary:\n",
    "#             print(\"decoder up5:\",x.shape)\n",
    "            \n",
    "#         x = self.final(x)\n",
    "#         if Summary:\n",
    "#             print(\"decoder final:\",x.shape)\n",
    "#         return x[:,0]  # [bs,H,W]\n",
    "    \n",
    "#     def close(self):\n",
    "#         for sf in self.sfs: sf.remove()\n",
    "\n",
    "\n",
    "# class UnetModel():\n",
    "#     def __init__(self,model,lr_cut,name='unet'):\n",
    "#         self.model,self.name = model,name\n",
    "#         self.lr_cut = lr_cut\n",
    "#         #print(self.model)\n",
    "\n",
    "#     def get_layer_groups(self, precompute):\n",
    "        \n",
    "#         #lgs = list(split_by_idxs(children(self.model.rn), [self.lr_cut]))\n",
    "#         lgs = list(children(self.model.rn))\n",
    "#         low=[lgs[0],lgs[1],lgs[2],lgs[4],lgs[5],lgs[7]]\n",
    "#         print(\"low:\",len(low))\n",
    "#         middle=[lgs[9],lgs[11]]\n",
    "#         print(\"middle:\",len(middle))\n",
    "#         high=[lgs[3],lgs[6],lgs[8],lgs[10],children(self.model)[1:]]\n",
    "#         print(\"high:\",len(high))\n",
    "#         groups=[]\n",
    "#         groups.append(low)\n",
    "#         groups.append(middle)\n",
    "#         groups.append(high)\n",
    "#         return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "class scSEModule(nn.Module):\n",
    "    def __init__(self, ch, re=4):\n",
    "        super().__init__()\n",
    "        self.cSE = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                 nn.Conv2d(ch,ch//re,1),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(ch//re,ch,1),\n",
    "                                 nn.Sigmoid()\n",
    "                               )\n",
    "        self.sSE = nn.Sequential(nn.Conv2d(ch,ch,1),\n",
    "                                 nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.cSE(x) + x * self.sSE(x)        \n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out,dropout_ratio=0):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1) # x_in 经过一个1x1卷积 调节通道数对齐\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "        self.scSE= scSEModule(n_out,re=4)\n",
    "        \n",
    "        self.dropout_ratio=dropout_ratio\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        cat_p= self.bn(F.relu(cat_p))\n",
    "        out=F.dropout2d(self.scSE(cat_p),self.dropout_ratio,training=self.training)\n",
    "        return out\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [3,6,8,10]]\n",
    "        \n",
    "        self.encoder_enhance=nn.Sequential( scSEModule(512,re=4),\n",
    "                                            )\n",
    "        \n",
    "        self.middle=nn.Conv2d(512,512,1,stride=1)\n",
    "        \n",
    "        # 刚开始时，将dropout 为0，观察训练是否过拟合后再决定增大丢弃率\n",
    "        self.up1 = UnetBlock(512,256,256,dropout_ratio=0.4)\n",
    "        self.up2 = UnetBlock(256,128,256,dropout_ratio=0.4)\n",
    "        self.up3 = UnetBlock(256,64,128, dropout_ratio=0.3)\n",
    "        self.up4 = UnetBlock(128,64,128, dropout_ratio=0.3)\n",
    "        self.up5 = nn.ConvTranspose2d(128, 96, 2, stride=2)\n",
    "        \n",
    "        self.final=nn.Conv2d(96,1,1)\n",
    "        \n",
    "        # Hypercolumn 未实现\n",
    "        \n",
    "    def forward(self,img,depth):\n",
    "        x = F.relu(self.rn(img))\n",
    "        \n",
    "        x = self.encoder_enhance(x)\n",
    "        x= self.middle(x)\n",
    "        \n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        x=F.dropout2d(x,0.1,training=self.training)\n",
    "        x = self.final(x)\n",
    "        \n",
    "        return x[:,0] # 注意: lovasz_hinge 要求的 preds shape为 [Bs,H,W] 而非[Bs,1,H,W], gt_mask的shape也必须为[Bs,H,W] \n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "\n",
    "# class UnetModel():\n",
    "#     def __init__(self,model,lr_cut,name='unet'):\n",
    "#         self.model,self.name = model,name\n",
    "#         self.lr_cut = lr_cut\n",
    "\n",
    "#     def get_layer_groups(self, precompute):\n",
    "#         lgs = list(split_by_idxs(children(self.model.rn), [self.lr_cut]))\n",
    "#         return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "class UnetModel():\n",
    "    def __init__(self,model,lr_cut,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "        self.lr_cut = lr_cut\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        \n",
    "        #lgs = list(split_by_idxs(children(self.model.rn), [self.lr_cut]))\n",
    "        lgs = list(children(self.model.rn))\n",
    "        low=[lgs[0],lgs[1],lgs[2],lgs[4],lgs[5],lgs[7]]\n",
    "        middle=[lgs[9],lgs[11]]\n",
    "        \n",
    "        \n",
    "        high=[lgs[3],lgs[6],lgs[8],lgs[10]]\n",
    "        decoder=children(self.model)[1:]\n",
    "        \n",
    "        groups=list()\n",
    "        groups.append(low)\n",
    "        groups.append(middle)\n",
    "        groups.append(high)\n",
    "        groups.append(decoder)\n",
    "        \n",
    "        \n",
    "        return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_tgs_model():\n",
    "    f = resnet34\n",
    "    cut,lr_cut = model_meta[f] # 8,6\n",
    "    m_base = get_base(f,cut)\n",
    "    m = to_gpu(Unet34(m_base))\n",
    "    models = UnetModel(m,lr_cut)\n",
    "    learn = ConvLearner(md, models)\n",
    "    \n",
    "    return learn\n",
    "\n",
    "def get_base(f,cut):\n",
    "    layers = cut_model(f(True), cut)\n",
    "    \n",
    "    num_channel={\"2\":64,\"4\":64,\"5\":128,\"6\":256}\n",
    "    decoder=[]\n",
    "    for i in range(len(layers)):\n",
    "        decoder.append(layers[i])\n",
    "        if i in set([2,4,5,6]):\n",
    "            decoder.append(nn.Sequential(  scSEModule(num_channel[str(i)],re=4)\n",
    "                                        ))\n",
    "       \n",
    "    return nn.Sequential(*decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tmp=get_tgs_model()\n",
    "\n",
    "# x=torch.randn(2,3,256,256)\n",
    "# tmp.train()\n",
    "# #tmp.eval()\n",
    "# tmp(Variable(x),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Stage --- do not run it if just test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 64]\n",
      "fold_id0\n",
      "8_fold_simple_resnet34_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857ff7c0aeda4023a670fa1605585b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   my_eval                     \n",
      "    0      0.441934   0.958804   0.816042  \n",
      "    1      0.492798   0.948809   0.816667                    \n",
      "    2      0.466649   0.936678   0.81                        \n",
      "    3      0.450486   0.910958   0.79625                     \n",
      "    4      0.421505   0.992493   0.804375                    \n",
      "    5      0.40334    1.013278   0.810208                    \n",
      "    6      0.39602    0.957814   0.814792                    \n",
      "    7      0.395973   0.927739   0.825833                    \n",
      "    8      0.373807   1.003346   0.823958                    \n",
      "    9      0.360309   1.011903   0.820625                    \n",
      "    10     0.379503   1.179822   0.803333                    \n",
      "    11     0.431641   0.918733   0.811875                    \n",
      "    12     0.456422   0.923998   0.8125                      \n",
      "    13     0.417033   0.95602    0.785417                    \n",
      "    14     0.399523   0.978365   0.792083                    \n",
      "    15     0.399098   0.985721   0.804583                    \n",
      "    16     0.369375   0.974772   0.798333                    \n",
      "    17     0.352707   1.021161   0.826875                    \n",
      "    18     0.348389   1.038873   0.807708                    \n",
      "    19     0.336616   1.029452   0.810625                    \n",
      "    20     0.345533   1.090036   0.80125                     \n",
      "    21     0.392389   1.075514   0.814167                    \n",
      "    22     0.414251   1.002535   0.814375                    \n",
      "    23     0.390181   0.975943   0.817917                    \n",
      "    24     0.367357   1.07056    0.8025                      \n",
      "    25     0.357775   1.011588   0.817083                    \n",
      "    26     0.334394   1.070281   0.808958                    \n",
      "    27     0.33141    1.016455   0.814375                    \n",
      "    28     0.336581   1.025393   0.809583                    \n",
      "    29     0.315242   1.037144   0.812708                    \n",
      "\n",
      "0.826875\n",
      "fold_id1\n",
      "8_fold_simple_resnet34_1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tgs/models/8_fold_simple_resnet34_1.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a96796001cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlovasz_hinge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_save_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/anaconda35/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/anaconda35/lib/python3.6/site-packages/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml/anaconda35/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tgs/models/8_fold_simple_resnet34_1.h5'"
     ]
    }
   ],
   "source": [
    "model = 'simple_resnet34'\n",
    "bst_acc=[]\n",
    "use_clr_min=20\n",
    "use_clr_div=10\n",
    "aug_tfms =[RandomFlip(tfm_y=TfmType.CLASS)]\n",
    "\n",
    "szs = [(256,64)]\n",
    "for sz,bs in szs:\n",
    "    print([sz,bs])\n",
    "    for i in range(kf-4) :\n",
    "        print(f'fold_id{i}')\n",
    "        \n",
    "        trn_x = np.array([f'trn_images/{o}' for o in train_folds[0]])\n",
    "        trn_y = np.array([f'trn_masks/{o}' for o in train_folds[0]])\n",
    "        val_x = [f'trn_images/{o}' for o in val_folds[0]]\n",
    "        val_y = [f'trn_masks/{o}' for o in val_folds[0]]\n",
    "        \n",
    "        tfms = tfms_from_model(resnet34, sz=sz, pad=0,crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "        datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms,test=tst_x,path=PATH)\n",
    "        md = ImageData(PATH, datasets, bs, num_workers=8, classes=None)\n",
    "        denorm = md.trn_ds.denorm\n",
    "        md.trn_dl.dataset = DepthDataset(md.trn_ds,dpth_dict)\n",
    "        md.val_dl.dataset = DepthDataset(md.val_ds,dpth_dict)\n",
    "        md.test_dl.dataset = DepthDataset(md.test_ds,dpth_dict)\n",
    "        learn = get_tgs_model() \n",
    "        learn.opt_fn = optim.Adam\n",
    "        learn.metrics=[my_eval]\n",
    "        pa = f'{kf}_fold_{model}_{i}'\n",
    "        print(pa)\n",
    "\n",
    "        lr=1e-2\n",
    "        wd=5e-7  #1e-7 \n",
    "        lrs = np.array([lr/50,lr/5,lr/10,lr])\n",
    "\n",
    "        learn.unfreeze()        \n",
    "        learn.crit = lovasz_hinge\n",
    "        learn.load(pa)\n",
    "        learn.fit(lrs/4,3, wds=wd, cycle_len=10,use_clr=(20,8),best_save_name=pa)\n",
    "\n",
    "        learn.load(pa)        \n",
    "        #Calcuating mean iou score\n",
    "        v_targ = md.val_ds.ds[:][1]\n",
    "        v_preds = np.zeros((len(v_targ),sz,sz))     \n",
    "        v_pred = learn.predict()\n",
    "        v_pred = to_np(torch.sigmoid(torch.from_numpy(v_pred)))\n",
    "        p = ((v_pred)>0.5).astype(np.uint8)\n",
    "        bst_acc.append(intersection_over_union_thresholds(v_targ,p))\n",
    "        print(bst_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst_acc,np.mean(bst_acc)#With 256\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "第5次训练  lr=1e-2\n",
    "        wd=5e-7  #1e-7 \n",
    "        lrs = np.array([lr/1,lr/1,lr/1,lr])/2\n",
    "\n",
    "epoch      trn_loss   val_loss   my_eval                    \n",
    "    0      1.361808   1.768405   0.563333  \n",
    "    1      1.271945   1.393701   0.6325                     \n",
    "    2      1.22546    1.103285   0.717292                   \n",
    "    3      1.100603   1.060564   0.721667                   \n",
    "    4      1.040772   0.971689   0.74375                    \n",
    "    5      1.000974   0.968966   0.744375                    \n",
    "    6      0.928853   0.874145   0.786458                    \n",
    "    7      0.898107   0.826325   0.78625                     \n",
    "    8      0.849922   0.829726   0.780417                    \n",
    "    9      0.793904   0.829265   0.793958                    \n",
    "    10     0.949336   0.999378   0.745417                    \n",
    "    11     1.087053   1.014289   0.727917                   \n",
    "    12     1.007459   0.994917   0.746042                   \n",
    "    13     0.989709   0.953513   0.773958                    \n",
    "    14     0.953903   0.922847   0.762917                    \n",
    "    15     0.913904   0.90461    0.753333                    \n",
    "    16     0.831526   0.853023   0.777708                    \n",
    "    17     0.804177   0.834908   0.794167                    \n",
    "    18     0.77297    0.860319   0.780417                    \n",
    "    19     0.737809   0.821741   0.795833                    \n",
    "    20     0.83418    0.942018   0.742708                    \n",
    "    21     0.943794   0.955236   0.768542                    \n",
    "    22     0.916414   1.000631   0.759583                    \n",
    "    23     0.888202   0.916103   0.779167                    \n",
    "    24     0.819576   0.84601    0.792292                    \n",
    "    25     0.793027   0.84377    0.770208                    \n",
    "    26     0.771033   0.799559   0.80125                     \n",
    "    27     0.735788   0.859489   0.773125                    \n",
    "    28     0.698546   0.835086   0.786458                    \n",
    "    29     0.699825   0.804718   0.805625   \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "第三次训练  lr=1e-2 wd=1e-7 lrs = np.array([lr/100,lr/10,lr/2,lr])/5\n",
    "\n",
    "epoch      trn_loss   val_loss   my_eval                     \n",
    "    0      0.724177   0.847318   0.81375   \n",
    "    1      0.57606    0.894748   0.813333                    \n",
    "    2      0.513421   0.854107   0.822917                    \n",
    "    3      0.464027   0.879192   0.820625                    \n",
    "    4      0.433076   0.990956   0.811042                    \n",
    "    5      0.43867    0.951688   0.804583                    \n",
    "    6      0.428984   0.920455   0.821042                    \n",
    "    7      0.401499   0.978546   0.819375                    \n",
    "    8      0.399173   0.97308    0.8175                      \n",
    "    9      0.397164   0.984055   0.82625                     \n",
    "    10     0.392509   0.956659   0.815625                    \n",
    "    11     0.412007   0.951582   0.81625                     \n",
    "    12     0.412894   0.900382   0.820833                    \n",
    "    13     0.399977   0.941249   0.816667                    \n",
    "    14     0.381477   0.992753   0.816458                    \n",
    "    15     0.372505   0.956275   0.814583                    \n",
    "    16     0.36326    1.025224   0.798958                    \n",
    "    17     0.357849   1.09216    0.806875                    \n",
    "    18     0.358487   0.987846   0.811458                    \n",
    "    19     0.353797   1.012645   0.810625                    \n",
    "    20     0.354088   1.048793   0.824792                    \n",
    "    21     0.393511   1.001458   0.807083                    \n",
    "    22     0.380662   1.022685   0.819792                    \n",
    "    23     0.364358   0.975018   0.804583                    \n",
    "    24     0.364864   1.047795   0.8125                      \n",
    "    25     0.351582   0.960161   0.805                       \n",
    "    26     0.34741    1.065952   0.804375                    \n",
    "    27     0.336437   1.05489    0.815417                    \n",
    "    28     0.336922   1.064214   0.807708                    \n",
    "    29     0.336781   1.069093   0.803542   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 备份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "class scSEModule(nn.Module):\n",
    "    def __init__(self, ch, re=4):\n",
    "        super().__init__()\n",
    "        self.cSE = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                 nn.Conv2d(ch,ch//re,1),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(ch//re,ch,1),\n",
    "                                 nn.Sigmoid()\n",
    "                               )\n",
    "        self.sSE = nn.Sequential(nn.Conv2d(ch,ch,1),\n",
    "                                 nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.cSE(x) + x * self.sSE(x)        \n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out,dropout_ratio=0):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1) # x_in 经过一个1x1卷积 调节通道数对齐\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "        self.scSE= scSEModule(n_out,re=4)\n",
    "        \n",
    "        self.dropout_ratio=dropout_ratio\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        cat_p= self.bn(F.relu(cat_p))\n",
    "        out=F.dropout2d(self.scSE(cat_p),self.dropout_ratio,training=self.training)\n",
    "        return out\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        \n",
    "        self.encoder_enhance=nn.Sequential( scSEModule(512,re=4),\n",
    "                                            nn.Dropout2d(p=0.1))\n",
    "        \n",
    "        self.middle=nn.Conv2d(512,512,1,stride=1)\n",
    "        \n",
    "        self.up1 = UnetBlock(512,256,128,dropout_ratio=0.2)\n",
    "        self.up2 = UnetBlock(128,128,128,dropout_ratio=0.2)\n",
    "        self.up3 = UnetBlock(128,64,128, dropout_ratio=0.2)\n",
    "        self.up4 = UnetBlock(128,64,128, dropout_ratio=0.2)\n",
    "        self.up5 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        \n",
    "        self.final=nn.Conv2d(64,1,1)\n",
    "        \n",
    "    def forward(self,img,depth):\n",
    "        x = F.relu(self.rn(img))\n",
    "        \n",
    "        x = self.encoder_enhance(x)\n",
    "        x= self.middle(x)\n",
    "        \n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        \n",
    "        x = self.final(x)\n",
    "        \n",
    "        return x[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "\n",
    "class UnetModel():\n",
    "    def __init__(self,model,lr_cut,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "        self.lr_cut = lr_cut\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [self.lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_tgs_model():\n",
    "#     f = resnet34\n",
    "    \n",
    "#     cut,lr_cut = model_meta[f] # 返回 8,6 # 这个6表示 0-5为底层特征层 6-7为中层特征层 分别执行不同的学习率\n",
    "#     #print(cut,lr_cut)\n",
    "    \n",
    "#     encoder = get_base(f,cut) # m_base 为 resNet34的前8个子mudule层，并封装成一个大的mudule \n",
    "#     m = to_gpu(Unet34(encoder))\n",
    "   \n",
    "#     models = UnetModel(m,lr_cut)\n",
    "#     return models\n",
    "# #     learn = ConvLearner(md, models)\n",
    "# #     return learn,models\n",
    "\n",
    "# def get_base(f,cut):\n",
    "#     layers = cut_model(f(True), cut)\n",
    "#     return nn.Sequential(*layers) # 取resNet34的前8个子mudule层，并封装成一个大的mudule # 改动: 在这些层之间插入一些新的层\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #??ConvLearner\n",
    "# a=get_tgs_model()\n",
    "# import torch \n",
    "\n",
    "# x=torch.randn(4,3,256,256)\n",
    "# out=a.model(Variable(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "encoder out: torch.Size([4, 512, 8, 8])\n",
    "decoder up1: torch.Size([4, 128, 16, 16])\n",
    "decoder up2: torch.Size([4, 128, 32, 32])\n",
    "decoder up3: torch.Size([4, 128, 64, 64])\n",
    "decoder up4: torch.Size([4, 128, 128, 128])\n",
    "decoder up5: torch.Size([4, 1, 256, 256])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改动1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (3500,) ['trn_masks/3cc59342bd.png' 'trn_masks/4e5d643b2f.png' 'trn_masks/55e9012561.png' ...\n",
      " 'trn_masks/8811181716.png' 'trn_masks/7d52a376a7.png' 'trn_masks/fe37eddf8e.png']\n",
      "['trn_masks/d2ea97ca4e.png', 'trn_masks/4ad8a63538.png', 'trn_masks/9a6c280d8d.png', 'trn_masks/0461a2fb30.png', 'trn_masks/e446b0b4b6.png', 'trn_masks/b2958f2747.png', 'trn_masks/dc0119712d.png', 'trn_masks/e41a05735d.png', 'trn_masks/6f438c26f8.png', 'trn_masks/5c33b65396.png', 'trn_masks/f503aaf699.png', 'trn_masks/6a1fe1a81e.png', 'trn_masks/c593c662f1.png', 'trn_masks/00cda0328c.png', 'trn_masks/1a8a17f220.png', 'trn_masks/3df62de11d.png', 'trn_masks/ec406285e8.png', 'trn_masks/ffb2ad3f94.png', 'trn_masks/b0e479668d.png', 'trn_masks/b7b83447c4.png']\n",
      "['trn_masks/3cc59342bd.png' 'trn_masks/4e5d643b2f.png' 'trn_masks/55e9012561.png' ...\n",
      " 'trn_masks/8811181716.png' 'trn_masks/7d52a376a7.png' 'trn_masks/fe37eddf8e.png']\n",
      "(101, 101, 3)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(type(md.trn_y),md.trn_y.shape,md.trn_y)\n",
    "\n",
    "print(md.val_y[:20])\n",
    "\n",
    "print(md.trn_ds.y)\n",
    "\n",
    "print(md.trn_ds.get_y(4).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bst_acc,np.mean(bst_acc)#With 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.814125, 0.8171250000000001, 0.8025, 0.8025, 0.82625], 0.8125)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bst_acc,np.mean(bst_acc) #With 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二次实验 ([0.814125, 0.8171250000000001, 0.8025, 0.8025, 0.82625], 0.8125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission - TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a607bb47074e1181a925f02ae6ceaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_fold_simple_resnet34_0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd21a7b3a834cdd976897f23fdd5b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_fold_simple_resnet34_0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f058f25da4345f9bf45ebeeae5f5455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAD4CAYAAADo84OlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = 'simple_resnet34'\n",
    "bst_acc=[]\n",
    "# use_clr_min=20\n",
    "# use_clr_div=10\n",
    "aug_tfms = [RandomFlip(tfm_y=TfmType.CLASS)]\n",
    "\n",
    "sz=256\n",
    "bs=32 # bs不能太大 否则内存溢出\n",
    "\n",
    "\n",
    "\n",
    "trn_x = np.array([f'trn_images/{o}' for o in train_folds[0]])\n",
    "trn_y = np.array([f'trn_masks/{o}' for o in train_folds[0]])\n",
    "val_x = [f'trn_images/{o}' for o in val_folds[0]]\n",
    "val_y = [f'trn_masks/{o}' for o in val_folds[0]]\n",
    "\n",
    "tfms = tfms_from_model(resnet34, sz=sz, pad=0,crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms,test=tst_x,path=PATH)\n",
    "md = ImageData(PATH, datasets, bs, num_workers=8, classes=None)\n",
    "denorm = md.trn_ds.denorm\n",
    "#md.trn_dl.dataset = DepthDataset(md.trn_ds,dpth_dict)\n",
    "#md.val_dl.dataset = DepthDataset(md.val_ds,dpth_dict)\n",
    "md.test_dl.dataset = DepthDataset(md.test_ds,dpth_dict)\n",
    " \n",
    "\n",
    "import gc\n",
    "\n",
    "model_num=0 # 0-4 依次导出所有模型的结果\n",
    "preds = np.zeros(shape = (18000,sz,sz))\n",
    "for o in [True,False]:\n",
    "    md.test_dl.dataset = TestFilesDataset(tst_x,tst_x,tfms[1],flip=o,path=PATH)\n",
    "    md.test_dl.dataset = DepthDataset(md.test_dl.dataset,dpth_dict)\n",
    "    \n",
    "    for i in tqdm_notebook(range(model_num,model_num+1)):\n",
    "        pa = f'{kf}_fold_{model}_{i}'\n",
    "        print(\"Load model from {}\".format(pa))\n",
    "        learn = get_tgs_model()\n",
    "        learn.load(pa)\n",
    "        pred = learn.predict(is_test=True)\n",
    "        pred = to_np(torch.sigmoid(torch.from_numpy(pred)))    \n",
    "        for im_idx,im in enumerate(pred):\n",
    "            preds[im_idx] += np.fliplr(im) if o else im\n",
    "        del pred\n",
    "        del learn\n",
    "        gc.collect()\n",
    "\n",
    "plt.imshow(((preds[18]/2)>0.5).astype(np.uint8)) # 随意显示一张测试图片的结果\n",
    "\n",
    "p = [cv2.resize(o/2,dsize=(101,101)) for o in preds]\n",
    "p = [(o>0.5).astype(np.uint8) for o in p]\n",
    "\n",
    "pred_dict = {id_[11:-4]:RLenc(p[i]) for i,id_ in tqdm_notebook(enumerate(tst_x))}\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('simple_k_fold_flipped_{}.csv'.format(model_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tst_images/69874e7963.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tst_x[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f10902f4588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyLupVbHHEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(((preds[18]/10)>0.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p = [cv2.resize(o/10,dsize=(101,101)) for o in preds]\n",
    "# p = [(o>0.5).astype(np.uint8) for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75b73d88880419096f66fbcde7fa7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pred_dict = {id_[11:-4]:RLenc(p[i]) for i,id_ in tqdm_notebook(enumerate(tst_x))}\n",
    "# sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "# sub.index.names = ['id']\n",
    "# sub.columns = ['rle_mask']\n",
    "# sub.to_csv('simple_k_fold_flipped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
