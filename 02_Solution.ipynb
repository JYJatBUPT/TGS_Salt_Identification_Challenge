{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ml/anaconda35/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet_resnet_v5.model\n",
      "Unet_resnet_v5.csv\n"
     ]
    }
   ],
   "source": [
    "version = 5\n",
    "basic_name = f'Unet_resnet_v{version}'\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "basic_path=\"\"\n",
    "train_df = pd.read_csv(basic_path+\"train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(basic_path+\"depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "\n",
    "\n",
    "len(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d55b5fa72564cc5b654aab41913fd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(basic_path+\"train/images/{}.png\".format(idx), color_mode = \"grayscale\"))# / 255 \n",
    "                          for idx in tqdm_notebook(train_df.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6feab8176b5540698b3a625860b5f9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(basic_path+\"train/masks/{}.png\".format(idx), color_mode = \"grayscale\"))# / 255 \n",
    "                         for idx in tqdm_notebook(train_df.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>images</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575d24d81d</th>\n",
       "      <td>843</td>\n",
       "      <td>[[134, 131, 134, 137, 136, 136, 136, 134, 123,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a266a2a9df</th>\n",
       "      <td>794</td>\n",
       "      <td>[[87, 96, 85, 57, 51, 92, 110, 122, 141, 141, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75efad62c1</th>\n",
       "      <td>468</td>\n",
       "      <td>[[145, 119, 83, 67, 70, 67, 56, 77, 113, 101, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34e51dba6a</th>\n",
       "      <td>727</td>\n",
       "      <td>[[138, 121, 101, 78, 52, 32, 21, 26, 47, 79, 1...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875705fb0</th>\n",
       "      <td>797</td>\n",
       "      <td>[[17, 20, 23, 27, 30, 32, 34, 36, 36, 36, 38, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782ae9b7e7</th>\n",
       "      <td>677</td>\n",
       "      <td>[[155, 158, 158, 157, 156, 156, 157, 157, 159,...</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9842f69f8d</th>\n",
       "      <td>907</td>\n",
       "      <td>[[112, 105, 102, 116, 141, 138, 130, 139, 106,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa94cfb806</th>\n",
       "      <td>754</td>\n",
       "      <td>[[129, 125, 121, 119, 119, 120, 123, 127, 130,...</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50d3073821</th>\n",
       "      <td>810</td>\n",
       "      <td>[[119, 136, 107, 83, 113, 126, 142, 128, 109, ...</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28f865caaa</th>\n",
       "      <td>147</td>\n",
       "      <td>[[110, 112, 113, 112, 109, 104, 100, 100, 97, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              z                                             images  \\\n",
       "id                                                                   \n",
       "575d24d81d  843  [[134, 131, 134, 137, 136, 136, 136, 134, 123,...   \n",
       "a266a2a9df  794  [[87, 96, 85, 57, 51, 92, 110, 122, 141, 141, ...   \n",
       "75efad62c1  468  [[145, 119, 83, 67, 70, 67, 56, 77, 113, 101, ...   \n",
       "34e51dba6a  727  [[138, 121, 101, 78, 52, 32, 21, 26, 47, 79, 1...   \n",
       "4875705fb0  797  [[17, 20, 23, 27, 30, 32, 34, 36, 36, 36, 38, ...   \n",
       "782ae9b7e7  677  [[155, 158, 158, 157, 156, 156, 157, 157, 159,...   \n",
       "9842f69f8d  907  [[112, 105, 102, 116, 141, 138, 130, 139, 106,...   \n",
       "aa94cfb806  754  [[129, 125, 121, 119, 119, 120, 123, 127, 130,...   \n",
       "50d3073821  810  [[119, 136, 107, 83, 113, 126, 142, 128, 109, ...   \n",
       "28f865caaa  147  [[110, 112, 113, 112, 109, 104, 100, 100, 97, ...   \n",
       "\n",
       "                                                        masks  \n",
       "id                                                             \n",
       "575d24d81d  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "a266a2a9df  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "75efad62c1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "34e51dba6a  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4875705fb0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "782ae9b7e7  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n",
       "9842f69f8d  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "aa94cfb806  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n",
       "50d3073821  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n",
       "28f865caaa  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 21):\n",
    "        if val * 20 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ml/anaconda35/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Coverage class')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAFdCAYAAABCR48WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqRK/H+mD81PP5sCFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ml/anaconda35/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Depth distribution')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAETCAYAAADDIPqYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxgRlScIYY0xQliSMMcYEZUnCGGNMUP8Pv9s2nSBmuZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the depth distributions\n",
    "\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.12, stratify=train_df.coverage_class, random_state= 1224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480,)\n",
      "(3520,)\n"
     ]
    }
   ],
   "source": [
    "print(ids_valid.shape)\n",
    "print(ids_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augment --- albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7040, 128, 128, 1)\n",
      "(480, 128, 128, 1)\n",
      "(7040, 128, 128, 1)\n",
      "(480, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7040, 128, 128, 3)\n",
      "(7040, 128, 128, 1)\n",
      "(480, 128, 128, 3)\n",
      "(480, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "mean= [0.485,0.456,0.406]\n",
    "std=  [0.229,0.224,0.225]\n",
    "\n",
    "x_train=np.concatenate((x_train-mean[2]/std[2],\n",
    "                  x_train-mean[1]/std[1],\n",
    "                  x_train-mean[0]/std[0]),axis=-1)\n",
    "\n",
    "x_valid=np.concatenate((x_valid-mean[2]/std[2],\n",
    "                  x_valid-mean[1]/std[1],\n",
    "                  x_valid-mean[0]/std[0]),axis=-1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch Bs,C,H,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7040, 3, 128, 128)\n",
      "(480, 3, 128, 128)\n",
      "(7040, 1, 128, 128)\n",
      "(480, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "x_train=np.transpose(x_train,[0,3,1,2]).astype(np.float32)\n",
    "y_train=np.transpose(y_train,[0,3,1,2]).astype(np.float32)\n",
    "\n",
    "x_valid=np.transpose(x_valid,[0,3,1,2]).astype(np.float32)\n",
    "y_valid=np.transpose(y_valid,[0,3,1,2]).astype(np.float32)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pytorch,torch.utils.data.Dataset\n",
    "# https://stackoverflow.com/questions/50052295/how-do-you-load-images-into-pytorch-dataloader\n",
    "\n",
    "class saltIDDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,preprocessed_images,train=True, preprocessed_masks=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        self.images = preprocessed_images\n",
    "        if self.train:\n",
    "            self.masks = preprocessed_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = None\n",
    "        if self.train:\n",
    "            mask = self.masks[idx]\n",
    "        return (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng samples: 7040\n",
      "Validation samples: 480\n"
     ]
    }
   ],
   "source": [
    "salt_ID_dataset_train = saltIDDataset(x_train, \n",
    "                                      train=True, \n",
    "                                      preprocessed_masks=y_train)\n",
    "\n",
    "salt_ID_dataset_val = saltIDDataset(x_valid, \n",
    "                                      train=True, \n",
    "                                      preprocessed_masks=y_valid)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=salt_ID_dataset_train, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=salt_ID_dataset_val, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "print(\"Trainng samples:\",train_loader.dataset.__len__())\n",
    "print(\"Validation samples:\",val_loader.dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "\"\"\"\n",
    "This script has been taken (and modified) from :\n",
    "https://github.com/ternaus/TernausNet\n",
    "@ARTICLE{arXiv:1801.05746,\n",
    "         author = {V. Iglovikov and A. Shvets},\n",
    "          title = {TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation},\n",
    "        journal = {ArXiv e-prints},\n",
    "         eprint = {1801.05746}, \n",
    "           year = 2018\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.BN=nn.BatchNorm2d(out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x=self.BN(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DecoderBlockV2(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
    "        super(DecoderBlockV2, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        if is_deconv:\n",
    "            \"\"\"\n",
    "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
    "                link https://distill.pub/2016/deconv-checkerboard/\n",
    "            \"\"\"\n",
    "\n",
    "            self.block = nn.Sequential(\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,padding=1),\n",
    "                ConvRelu(out_channels, out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNetResNet(nn.Module):\n",
    "    \"\"\"PyTorch U-Net model using ResNet(34, 101 or 152) encoder.\n",
    "    UNet: https://arxiv.org/abs/1505.04597\n",
    "    ResNet: https://arxiv.org/abs/1512.03385\n",
    "    Proposed by Alexander Buslaev: https://www.linkedin.com/in/al-buslaev/\n",
    "    Args:\n",
    "            encoder_depth (int): Depth of a ResNet encoder (34, 101 or 152).\n",
    "            num_classes (int): Number of output classes.\n",
    "            num_filters (int, optional): Number of filters in the last layer of decoder. Defaults to 32.\n",
    "            dropout_2d (float, optional): Probability factor of dropout layer before output layer. Defaults to 0.2.\n",
    "            pretrained (bool, optional):\n",
    "                False - no pre-trained weights are being used.\n",
    "                True  - ResNet encoder is pre-trained on ImageNet.\n",
    "                Defaults to False.\n",
    "            is_deconv (bool, optional):\n",
    "                False: bilinear interpolation is used in decoder.\n",
    "                True: deconvolution is used in decoder.\n",
    "                Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_depth, num_classes, num_filters=32, dropout_2d_ration=0.5,\n",
    "                 pretrained=False, is_deconv=True):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_2d_ratio = dropout_2d_ration\n",
    "\n",
    "        if encoder_depth == 34:\n",
    "            self.encoder = torchvision.models.resnet34(pretrained=pretrained)\n",
    "            bottom_channel_nr = 512\n",
    "        elif encoder_depth == 101:\n",
    "            self.encoder = torchvision.models.resnet101(pretrained=pretrained)\n",
    "            bottom_channel_nr = 2048\n",
    "        elif encoder_depth == 152:\n",
    "            self.encoder = torchvision.models.resnet152(pretrained=pretrained)\n",
    "            bottom_channel_nr = 2048\n",
    "        else:\n",
    "            raise NotImplementedError('only 34, 101, 152 version of Resnet are implemented')\n",
    "        \n",
    "        #print(self.encoder)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1 = nn.Sequential(self.encoder.conv1,self.encoder.bn1,self.encoder.relu)\n",
    "\n",
    "        self.conv2 = self.encoder.layer1\n",
    "\n",
    "        self.conv3 = self.encoder.layer2\n",
    "\n",
    "        self.conv4 = self.encoder.layer3\n",
    "\n",
    "        self.middle = self.encoder.layer4\n",
    "\n",
    "        \n",
    "        self.dec5 = DecoderBlockV2(512, 512, 256, is_deconv)\n",
    "        \n",
    "        self.dec4 = DecoderBlockV2(512, 256, 128, is_deconv)\n",
    "        \n",
    "        self.dec3 = DecoderBlockV2(256, 128,  64, is_deconv)\n",
    "        \n",
    "        self.dec2 = DecoderBlockV2(192,  96,  48, is_deconv)\n",
    "        \n",
    "        \n",
    "        self.dec0 = ConvRelu(48, 32)\n",
    "        \n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv1 = self.conv1(x)\n",
    "        conv1=F.dropout2d(conv1, p=self.dropout_2d_ratio/2,training=self.training)\n",
    "        \n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv2=F.dropout2d(conv2, p=self.dropout_2d_ratio,training=self.training)\n",
    "        \n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv3=F.dropout2d(conv3, p=self.dropout_2d_ratio,training=self.training)\n",
    "        \n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv4=F.dropout2d(conv4, p=self.dropout_2d_ratio,training=self.training)\n",
    "        \n",
    "        middle = self.middle(conv4)\n",
    "        middle=F.dropout2d(middle, p=self.dropout_2d_ratio//2,training=self.training)\n",
    "        \n",
    "        Summary=False\n",
    "        if Summary:\n",
    "            print(\"x:\",x.shape)\n",
    "            print(\"conv1:\",conv1.shape)\n",
    "            print(\"conv2:\",conv2.shape)\n",
    "            print(\"conv3:\",conv3.shape)\n",
    "            print(\"conv4:\",conv4.shape)\n",
    "            print(\"middle:\",middle.shape)\n",
    "        \n",
    "        \n",
    "        dec5 = self.dec5(middle)\n",
    "    \n",
    "        tmp=torch.cat([dec5, conv4],1)\n",
    "        tmp=F.dropout2d(tmp, p=self.dropout_2d_ratio,training=self.training)\n",
    "        dec4 = self.dec4(tmp)\n",
    "        \n",
    "        tmp=torch.cat([dec4, conv3], 1)\n",
    "        tmp=F.dropout2d(tmp, p=self.dropout_2d_ratio,training=self.training)\n",
    "        dec3 = self.dec3(tmp)\n",
    "        \n",
    "        tmp=torch.cat([dec3, conv2, conv1], 1)\n",
    "        tmp=F.dropout2d(tmp, p=self.dropout_2d_ratio,training=self.training)\n",
    "        dec2 = self.dec2(tmp)\n",
    "       \n",
    "        tmp=F.dropout2d(dec2, p=self.dropout_2d_ratio,training=self.training)\n",
    "        dec0 = self.dec0(tmp)\n",
    "        \n",
    "        logits=self.final(F.dropout2d(dec0, p=self.dropout_2d_ratio/2,training=self.training))\n",
    "        \n",
    "        \n",
    "        if Summary:\n",
    "            print(\"dec5:\",dec5.shape)\n",
    "            print(\"dec4:\",dec4.shape)\n",
    "            print(\"dec3:\",dec3.shape)\n",
    "            print(\"dec2:\",dec2.shape)\n",
    "            print(\"dec0:\",dec0.shape)\n",
    "            print(\"logits:\",logits.shape)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import time \n",
    "# since=time.time()\n",
    "\n",
    "# x=torch.randn(4,3,128,128).cuda()\n",
    "\n",
    "# model=UNetResNet(encoder_depth=34,num_classes=1,num_filters=32, dropout_2d_ration=0.5,pretrained=False)\n",
    "\n",
    "# model.cuda()\n",
    "\n",
    "\n",
    "# out=model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0  # \n",
    "        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred): \n",
    "    # labeltorch.Tensor [bs,C,H,W] label.detach().cpu().numpy() pred\n",
    "    return get_iou_vector(label, pred>0.5)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return get_iou_vector(label, pred >0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _label=(torch.randn(32,101,101,1)>0.5).numpy()\n",
    "# _logits=(torch.randn(32,101,101,1)>0.5).numpy()\n",
    "# my_iou_metric(_label,_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ArgParser(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.MaxEpoch=100\n",
    "        self.LR_Policy=\"MultiStage\"\n",
    "        \n",
    "        self.n_gpus=1\n",
    "        \n",
    "        self.load_pretrained_model=False\n",
    "        self.pretarined_model_path=\"Results\"\n",
    "        \n",
    "        self.device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.start_save_epoch=80\n",
    "        self.save_step=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "        \n",
    "def custom_weights_init(m):\n",
    "    pass \n",
    "\n",
    "def save_checkpoint(state, is_best, path,args):\n",
    "    torch.save(state, os.path.join(args.pretarined_model_path ,'MM_best.pt'))\n",
    "\n",
    "    \n",
    "def train(model,train_loader,optimizer,criterion,args,epoch,class_weights):\n",
    "    since=time.time()\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        \n",
    "        images, masks = images.to(args.device), masks.to(args.device)\n",
    "        images, masks = Variable(images), Variable(masks)\n",
    "        \n",
    "        logits = model(images)\n",
    "        \n",
    "        loss = criterion(logits, masks)\n",
    "        \n",
    "        train_losses.append(loss.data)\n",
    "        \n",
    "        #dice_loss = bioloss.dice_error(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    now=time.time()\n",
    "    mean_loss=np.mean(train_losses)\n",
    "    print(\"Mean Train Loss:{},escaped time:{}\".format(mean_loss,now-since))\n",
    "    return mean_loss\n",
    "\n",
    "def test(model,test_loader,criterion,args,epoch,class_weights):\n",
    "    since=time.time()\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    ious=[]\n",
    "    \n",
    "    for batch_idx, (images, masks) in enumerate(test_loader):\n",
    "        \n",
    "        images, masks = images.to(args.device), masks.to(args.device)\n",
    "        images, masks = Variable(images), Variable(masks)\n",
    "        \n",
    "        logits = model(images)\n",
    "        \n",
    "        loss= criterion(logits, masks)\n",
    "        \n",
    "        test_losses.append(loss.data)\n",
    "        \n",
    "        pred=torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        iou_btach=my_iou_metric(masks.detach().cpu().numpy(), pred)\n",
    "        ious.append(iou_btach)\n",
    "        \n",
    "    now=time.time()\n",
    "    mean_loss=np.mean(test_losses)\n",
    "    mean_iou=np.mean(ious)\n",
    "    print(\"Mean Val Loss:{},Mean IOU:{}, escaped time:{}\".format(mean_loss,mean_iou,now-since))\n",
    "            \n",
    "    return mean_loss,mean_iou\n",
    "   \n",
    "train_losses_history=[]\n",
    "val_losses_history=[]\n",
    "\n",
    "def main():\n",
    "    \n",
    "    args=ArgParser()\n",
    "    \n",
    "    torch.cuda.manual_seed_all(4200)# \n",
    "    np.random.seed(133700)\n",
    "    \n",
    "\n",
    "    model=UNetResNet(encoder_depth=34,num_classes=1,num_filters=32, dropout_2d_ration=0.5,pretrained=True)\n",
    "    \n",
    "#     gpu_ids=range(args.n_gpus)\n",
    "#     model=nn.parallel.DataParallel(model,device_ids=gpu_ids)\n",
    "    \n",
    "    if args.load_pretrained_model==True:\n",
    "        state=torch.load(args.pretarined_model_path)\n",
    "        model.load_state_dict(state)\n",
    "    else:\n",
    "        model.apply(custom_weights_init)    \n",
    "    \n",
    "    # deploy model to GPU or CPU\n",
    "    model.to(args.device)\n",
    "    \n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60,80], gamma=0.2)\n",
    "    \n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion=nn.MSELoss()\n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    \n",
    "    \n",
    "    class_weights=[0.5,0.5] \n",
    "    \n",
    "    best_metric=-1  # \n",
    "    metirc_history=[]\n",
    "    for epoch in range(1,args.MaxEpoch):\n",
    "        \n",
    "        \n",
    "        mean_train_loss_=train(model,train_loader,optimizer,criterion,args,epoch,class_weights)\n",
    "        train_losses_history.append(mean_train_loss_)\n",
    "        \n",
    "        mean_val_loss_,mean_iou_=test(model,val_loader,criterion,args,epoch,class_weights)\n",
    "        val_losses_history.append(mean_val_loss_)\n",
    "        \n",
    "        if  epoch>=args.start_save_epoch :\n",
    "            if mean_iou_>best_metric:\n",
    "                best_metric=mean_iou_\n",
    "                is_best=True\n",
    "                save_checkpoint(model.state_dict(), is_best, args.pretarined_model_path,args)\n",
    "            else:\n",
    "                is_best=False\n",
    "                if epoch % args.save_step ==0:\n",
    "                    torch.save(model.state_dict(),\"Results/MM_{}.pt\".format(epoch))\n",
    "        scheduler.step()\n",
    "        \n",
    "    torch.save(model.state_dict(),\"Results/MM.pt\")\n",
    "    return model\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.torch/models/resnet34-333f7ec4.pth\n",
      "100%|| 87306240/87306240 [00:06<00:00, 13668385.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Loss:0.5540709495544434,escaped time:54.08536505699158\n",
      "Mean Val Loss:0.7726391553878784,Mean IOU:0.38958333333333334, escaped time:1.2559618949890137\n",
      "Mean Train Loss:0.43623435497283936,escaped time:54.02131962776184\n",
      "Mean Val Loss:0.6051608324050903,Mean IOU:0.23854166666666668, escaped time:1.251237154006958\n",
      "Mean Train Loss:0.38836508989334106,escaped time:54.020124197006226\n",
      "Mean Val Loss:0.5621757507324219,Mean IOU:0.38958333333333334, escaped time:1.2512695789337158\n",
      "Mean Train Loss:0.3682606816291809,escaped time:54.02497887611389\n",
      "Mean Val Loss:0.31632718443870544,Mean IOU:0.5804166666666667, escaped time:1.2517454624176025\n",
      "Mean Train Loss:0.3340160846710205,escaped time:54.03168344497681\n",
      "Mean Val Loss:0.2828940153121948,Mean IOU:0.6058333333333333, escaped time:1.2516093254089355\n",
      "Mean Train Loss:0.3185363709926605,escaped time:54.0247642993927\n",
      "Mean Val Loss:0.4714888334274292,Mean IOU:0.42937499999999995, escaped time:1.251859188079834\n",
      "Mean Train Loss:0.30028781294822693,escaped time:54.02527165412903\n",
      "Mean Val Loss:0.2455773949623108,Mean IOU:0.6258333333333332, escaped time:1.2510836124420166\n",
      "Mean Train Loss:0.29367947578430176,escaped time:54.02703619003296\n",
      "Mean Val Loss:0.2590627074241638,Mean IOU:0.6304166666666667, escaped time:1.2507460117340088\n",
      "Mean Train Loss:0.2790226340293884,escaped time:54.019510984420776\n",
      "Mean Val Loss:0.37636563181877136,Mean IOU:0.5285416666666667, escaped time:1.2495582103729248\n",
      "Mean Train Loss:0.27840545773506165,escaped time:54.02228784561157\n",
      "Mean Val Loss:0.23577100038528442,Mean IOU:0.6233333333333333, escaped time:1.2506933212280273\n",
      "Mean Train Loss:0.2669675946235657,escaped time:54.02676200866699\n",
      "Mean Val Loss:0.2358911633491516,Mean IOU:0.6308333333333334, escaped time:1.2496497631072998\n",
      "Mean Train Loss:0.25923606753349304,escaped time:54.02334141731262\n",
      "Mean Val Loss:0.19753985106945038,Mean IOU:0.6627083333333333, escaped time:1.2484304904937744\n",
      "Mean Train Loss:0.25239408016204834,escaped time:54.02641487121582\n",
      "Mean Val Loss:0.19582022726535797,Mean IOU:0.65, escaped time:1.2499430179595947\n",
      "Mean Train Loss:0.24373094737529755,escaped time:58.79288172721863\n",
      "Mean Val Loss:0.27497056126594543,Mean IOU:0.534375, escaped time:1.253140926361084\n",
      "Mean Train Loss:0.2344416230916977,escaped time:54.05260872840881\n",
      "Mean Val Loss:0.20420828461647034,Mean IOU:0.6720833333333333, escaped time:1.252596378326416\n",
      "Mean Train Loss:0.24229122698307037,escaped time:54.04895257949829\n",
      "Mean Val Loss:0.17967139184474945,Mean IOU:0.6745833333333332, escaped time:1.2492053508758545\n",
      "Mean Train Loss:0.2298789918422699,escaped time:54.04609966278076\n",
      "Mean Val Loss:0.1769411712884903,Mean IOU:0.6802083333333333, escaped time:1.2502214908599854\n",
      "Mean Train Loss:0.22268687188625336,escaped time:54.04057741165161\n",
      "Mean Val Loss:0.17266981303691864,Mean IOU:0.6664583333333332, escaped time:1.2518947124481201\n",
      "Mean Train Loss:0.21539898216724396,escaped time:54.04276657104492\n",
      "Mean Val Loss:0.1745489537715912,Mean IOU:0.6772916666666667, escaped time:1.2499735355377197\n",
      "Mean Train Loss:0.21628765761852264,escaped time:54.03961205482483\n",
      "Mean Val Loss:0.17817333340644836,Mean IOU:0.688125, escaped time:1.2510852813720703\n",
      "Mean Train Loss:0.21281853318214417,escaped time:54.037471294403076\n",
      "Mean Val Loss:0.15978960692882538,Mean IOU:0.6964583333333334, escaped time:1.2503013610839844\n",
      "Mean Train Loss:0.21383056044578552,escaped time:54.04096794128418\n",
      "Mean Val Loss:0.15956030786037445,Mean IOU:0.6925000000000001, escaped time:1.250387191772461\n",
      "Mean Train Loss:0.2067897468805313,escaped time:54.03955054283142\n",
      "Mean Val Loss:0.15698400139808655,Mean IOU:0.7006249999999999, escaped time:1.2500579357147217\n",
      "Mean Train Loss:0.1958710104227066,escaped time:54.0321729183197\n",
      "Mean Val Loss:0.16957403719425201,Mean IOU:0.6991666666666667, escaped time:1.2505671977996826\n",
      "Mean Train Loss:0.19888165593147278,escaped time:54.03327012062073\n",
      "Mean Val Loss:0.17216788232326508,Mean IOU:0.6814583333333334, escaped time:1.2513220310211182\n",
      "Mean Train Loss:0.20139780640602112,escaped time:54.03866791725159\n",
      "Mean Val Loss:0.15031133592128754,Mean IOU:0.7089583333333334, escaped time:1.2495949268341064\n",
      "Mean Train Loss:0.19096733629703522,escaped time:54.03749990463257\n",
      "Mean Val Loss:0.18064281344413757,Mean IOU:0.6529166666666666, escaped time:1.2504031658172607\n",
      "Mean Train Loss:0.1864057034254074,escaped time:54.036667823791504\n",
      "Mean Val Loss:0.1928664743900299,Mean IOU:0.6575000000000001, escaped time:1.2492880821228027\n",
      "Mean Train Loss:0.18959131836891174,escaped time:54.0347158908844\n",
      "Mean Val Loss:0.16826696693897247,Mean IOU:0.7145833333333332, escaped time:1.2505662441253662\n",
      "Mean Train Loss:0.18504567444324493,escaped time:54.02831172943115\n",
      "Mean Val Loss:0.15819263458251953,Mean IOU:0.7133333333333333, escaped time:1.251605749130249\n",
      "Mean Train Loss:0.1831309199333191,escaped time:53.547821283340454\n",
      "Mean Val Loss:0.15769973397254944,Mean IOU:0.7133333333333333, escaped time:1.2496089935302734\n",
      "Mean Train Loss:0.18411965668201447,escaped time:53.99665594100952\n",
      "Mean Val Loss:0.1767435222864151,Mean IOU:0.6966666666666665, escaped time:1.2489030361175537\n",
      "Mean Train Loss:0.17891256511211395,escaped time:53.99392342567444\n",
      "Mean Val Loss:0.15472689270973206,Mean IOU:0.7124999999999999, escaped time:1.2498652935028076\n",
      "Mean Train Loss:0.17968054115772247,escaped time:53.9948205947876\n",
      "Mean Val Loss:0.16846182942390442,Mean IOU:0.6979166666666667, escaped time:1.2494351863861084\n",
      "Mean Train Loss:0.17297731339931488,escaped time:54.00355863571167\n",
      "Mean Val Loss:0.1632455736398697,Mean IOU:0.7056250000000001, escaped time:1.2496247291564941\n",
      "Mean Train Loss:0.1703338325023651,escaped time:53.99603867530823\n",
      "Mean Val Loss:0.14686398208141327,Mean IOU:0.7164583333333333, escaped time:1.2497053146362305\n",
      "Mean Train Loss:0.17666691541671753,escaped time:53.99321985244751\n",
      "Mean Val Loss:0.14901010692119598,Mean IOU:0.7100000000000001, escaped time:1.2495439052581787\n",
      "Mean Train Loss:0.1639014035463333,escaped time:53.99130964279175\n",
      "Mean Val Loss:0.15231920778751373,Mean IOU:0.7110416666666667, escaped time:1.2495458126068115\n",
      "Mean Train Loss:0.17516137659549713,escaped time:53.992810010910034\n",
      "Mean Val Loss:0.15785354375839233,Mean IOU:0.7135416666666666, escaped time:1.2501044273376465\n",
      "Mean Train Loss:0.16020824015140533,escaped time:53.99191427230835\n",
      "Mean Val Loss:0.15307192504405975,Mean IOU:0.7122916666666668, escaped time:1.2499909400939941\n",
      "Mean Train Loss:0.17042964696884155,escaped time:53.993608236312866\n",
      "Mean Val Loss:0.14447744190692902,Mean IOU:0.7210416666666667, escaped time:1.2498371601104736\n",
      "Mean Train Loss:0.15619777143001556,escaped time:53.991920471191406\n",
      "Mean Val Loss:0.16861926019191742,Mean IOU:0.7035416666666666, escaped time:1.248903512954712\n",
      "Mean Train Loss:0.15508109331130981,escaped time:53.99457287788391\n",
      "Mean Val Loss:0.14691422879695892,Mean IOU:0.7197916666666667, escaped time:1.250195026397705\n",
      "Mean Train Loss:0.1544504314661026,escaped time:53.99071168899536\n",
      "Mean Val Loss:0.15751387178897858,Mean IOU:0.7266666666666667, escaped time:1.2498960494995117\n",
      "Mean Train Loss:0.1600969135761261,escaped time:53.992786169052124\n",
      "Mean Val Loss:0.1549932211637497,Mean IOU:0.7222916666666666, escaped time:1.2485694885253906\n",
      "Mean Train Loss:0.1527092605829239,escaped time:53.98890733718872\n",
      "Mean Val Loss:0.15781711041927338,Mean IOU:0.73125, escaped time:1.2488245964050293\n",
      "Mean Train Loss:0.15407319366931915,escaped time:53.99318480491638\n",
      "Mean Val Loss:0.14953915774822235,Mean IOU:0.7354166666666668, escaped time:1.2493104934692383\n",
      "Mean Train Loss:0.14474569261074066,escaped time:53.99373173713684\n",
      "Mean Val Loss:0.16938500106334686,Mean IOU:0.7339583333333334, escaped time:1.250058889389038\n",
      "Mean Train Loss:0.15244752168655396,escaped time:53.99789643287659\n",
      "Mean Val Loss:0.16493965685367584,Mean IOU:0.7133333333333332, escaped time:1.2500052452087402\n",
      "Mean Train Loss:0.14717575907707214,escaped time:53.99268960952759\n",
      "Mean Val Loss:0.1527937352657318,Mean IOU:0.7158333333333334, escaped time:1.250504970550537\n",
      "Mean Train Loss:0.14622536301612854,escaped time:53.993393898010254\n",
      "Mean Val Loss:0.14222761988639832,Mean IOU:0.7427083333333334, escaped time:1.2492990493774414\n",
      "Mean Train Loss:0.13837271928787231,escaped time:53.99429535865784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Val Loss:0.16647934913635254,Mean IOU:0.7345833333333334, escaped time:1.2502100467681885\n",
      "Mean Train Loss:0.13984285295009613,escaped time:53.9946506023407\n",
      "Mean Val Loss:0.1375289112329483,Mean IOU:0.7454166666666667, escaped time:1.249680995941162\n",
      "Mean Train Loss:0.14108605682849884,escaped time:53.99669122695923\n",
      "Mean Val Loss:0.14173589646816254,Mean IOU:0.7395833333333334, escaped time:1.2501304149627686\n",
      "Mean Train Loss:0.13556349277496338,escaped time:53.9932165145874\n",
      "Mean Val Loss:0.1612665057182312,Mean IOU:0.7075, escaped time:1.2493062019348145\n",
      "Mean Train Loss:0.14074432849884033,escaped time:53.993431091308594\n",
      "Mean Val Loss:0.18343286216259003,Mean IOU:0.7254166666666666, escaped time:1.248948574066162\n",
      "Mean Train Loss:0.1342318058013916,escaped time:53.99168133735657\n",
      "Mean Val Loss:0.14576439559459686,Mean IOU:0.7333333333333332, escaped time:1.2491700649261475\n",
      "Mean Train Loss:0.12992465496063232,escaped time:53.995802879333496\n",
      "Mean Val Loss:0.14127740263938904,Mean IOU:0.7316666666666669, escaped time:1.249760389328003\n",
      "Mean Train Loss:0.1343461275100708,escaped time:53.99208307266235\n",
      "Mean Val Loss:0.1805286407470703,Mean IOU:0.7018749999999999, escaped time:1.2486705780029297\n",
      "Mean Train Loss:0.1288178563117981,escaped time:53.99321508407593\n",
      "Mean Val Loss:0.16209833323955536,Mean IOU:0.7291666666666666, escaped time:1.2490713596343994\n",
      "Mean Train Loss:0.1273878514766693,escaped time:53.99721050262451\n",
      "Mean Val Loss:0.16983671486377716,Mean IOU:0.7102083333333333, escaped time:1.250086784362793\n",
      "Mean Train Loss:0.10928010940551758,escaped time:53.993162393569946\n",
      "Mean Val Loss:0.14827172458171844,Mean IOU:0.750625, escaped time:1.249584674835205\n",
      "Mean Train Loss:0.1018659770488739,escaped time:54.00089383125305\n",
      "Mean Val Loss:0.1573040783405304,Mean IOU:0.754375, escaped time:1.249558687210083\n",
      "Mean Train Loss:0.09588274359703064,escaped time:53.98824644088745\n",
      "Mean Val Loss:0.16236774623394012,Mean IOU:0.7533333333333334, escaped time:1.2483036518096924\n",
      "Mean Train Loss:0.09366657584905624,escaped time:53.9950909614563\n",
      "Mean Val Loss:0.1583521068096161,Mean IOU:0.7531250000000002, escaped time:1.2502458095550537\n",
      "Mean Train Loss:0.09389252960681915,escaped time:53.98606991767883\n",
      "Mean Val Loss:0.15989698469638824,Mean IOU:0.7441666666666668, escaped time:1.248579978942871\n",
      "Mean Train Loss:0.09193607419729233,escaped time:53.99028277397156\n",
      "Mean Val Loss:0.16126157343387604,Mean IOU:0.7624999999999998, escaped time:1.2484362125396729\n",
      "Mean Train Loss:0.08882434666156769,escaped time:53.99199891090393\n",
      "Mean Val Loss:0.16556255519390106,Mean IOU:0.7581249999999998, escaped time:1.2497355937957764\n",
      "Mean Train Loss:0.08853708952665329,escaped time:53.99450349807739\n",
      "Mean Val Loss:0.16337087750434875,Mean IOU:0.7552083333333334, escaped time:1.2505578994750977\n",
      "Mean Train Loss:0.08418674767017365,escaped time:53.98927688598633\n",
      "Mean Val Loss:0.18506579101085663,Mean IOU:0.7585416666666667, escaped time:1.2485392093658447\n",
      "Mean Train Loss:0.08420483767986298,escaped time:53.9950156211853\n",
      "Mean Val Loss:0.17349503934383392,Mean IOU:0.7427083333333333, escaped time:1.249333143234253\n",
      "Mean Train Loss:0.08172591030597687,escaped time:53.99382734298706\n",
      "Mean Val Loss:0.18165431916713715,Mean IOU:0.7420833333333333, escaped time:1.2501866817474365\n",
      "Mean Train Loss:0.08130761235952377,escaped time:53.991896629333496\n",
      "Mean Val Loss:0.1751256287097931,Mean IOU:0.7520833333333333, escaped time:1.2493984699249268\n",
      "Mean Train Loss:0.08279770612716675,escaped time:53.99316453933716\n",
      "Mean Val Loss:0.16201284527778625,Mean IOU:0.7495833333333335, escaped time:1.2492148876190186\n",
      "Mean Train Loss:0.08137410134077072,escaped time:53.99519371986389\n",
      "Mean Val Loss:0.18375660479068756,Mean IOU:0.7308333333333333, escaped time:1.248816967010498\n",
      "Mean Train Loss:0.0792095810174942,escaped time:53.99450874328613\n",
      "Mean Val Loss:0.1763026863336563,Mean IOU:0.7572916666666667, escaped time:1.2496535778045654\n",
      "Mean Train Loss:0.07780354470014572,escaped time:53.98979830741882\n",
      "Mean Val Loss:0.18397685885429382,Mean IOU:0.7435416666666667, escaped time:1.2506322860717773\n",
      "Mean Train Loss:0.07808338850736618,escaped time:53.994508266448975\n",
      "Mean Val Loss:0.1855776607990265,Mean IOU:0.7589583333333334, escaped time:1.2497780323028564\n",
      "Mean Train Loss:0.07533860951662064,escaped time:53.99414014816284\n",
      "Mean Val Loss:0.16903847455978394,Mean IOU:0.7627083333333332, escaped time:1.2492930889129639\n",
      "Mean Train Loss:0.07626578956842422,escaped time:53.98732089996338\n",
      "Mean Val Loss:0.18436406552791595,Mean IOU:0.7535416666666668, escaped time:1.2500710487365723\n",
      "Mean Train Loss:0.07429144531488419,escaped time:53.99082660675049\n",
      "Mean Val Loss:0.19277122616767883,Mean IOU:0.7489583333333332, escaped time:1.2487714290618896\n",
      "Mean Train Loss:0.07455118000507355,escaped time:53.994091272354126\n",
      "Mean Val Loss:0.18079118430614471,Mean IOU:0.7560416666666667, escaped time:1.248382568359375\n",
      "Mean Train Loss:0.07172612100839615,escaped time:53.99499225616455\n",
      "Mean Val Loss:0.18725696206092834,Mean IOU:0.7585416666666668, escaped time:1.2492139339447021\n",
      "Mean Train Loss:0.0694475769996643,escaped time:53.988917112350464\n",
      "Mean Val Loss:0.1884649097919464,Mean IOU:0.7502083333333333, escaped time:1.249981164932251\n",
      "Mean Train Loss:0.06942305713891983,escaped time:53.993584871292114\n",
      "Mean Val Loss:0.17932894825935364,Mean IOU:0.7572916666666667, escaped time:1.249528408050537\n",
      "Mean Train Loss:0.07009261846542358,escaped time:53.9889030456543\n",
      "Mean Val Loss:0.18726730346679688,Mean IOU:0.7464583333333332, escaped time:1.2492356300354004\n",
      "Mean Train Loss:0.0678582563996315,escaped time:53.993056297302246\n",
      "Mean Val Loss:0.18935523927211761,Mean IOU:0.751875, escaped time:1.2491636276245117\n",
      "Mean Train Loss:0.06840715557336807,escaped time:53.992758989334106\n",
      "Mean Val Loss:0.18416354060173035,Mean IOU:0.7518749999999998, escaped time:1.2494456768035889\n",
      "Mean Train Loss:0.06970344483852386,escaped time:53.99179482460022\n",
      "Mean Val Loss:0.18719561398029327,Mean IOU:0.7520833333333332, escaped time:1.2487149238586426\n",
      "Mean Train Loss:0.07025416195392609,escaped time:53.99276566505432\n",
      "Mean Val Loss:0.18274100124835968,Mean IOU:0.7508333333333331, escaped time:1.2500474452972412\n",
      "Mean Train Loss:0.06879446655511856,escaped time:53.998114585876465\n",
      "Mean Val Loss:0.1737624853849411,Mean IOU:0.7568749999999999, escaped time:1.2494056224822998\n",
      "Mean Train Loss:0.06877940893173218,escaped time:53.995229959487915\n",
      "Mean Val Loss:0.19103701412677765,Mean IOU:0.7535416666666667, escaped time:1.2487506866455078\n",
      "Mean Train Loss:0.070625901222229,escaped time:53.99629759788513\n",
      "Mean Val Loss:0.19070786237716675,Mean IOU:0.7443750000000001, escaped time:1.2483327388763428\n",
      "Mean Train Loss:0.06877501308917999,escaped time:53.98772120475769\n",
      "Mean Val Loss:0.19036081433296204,Mean IOU:0.7531249999999999, escaped time:1.2491626739501953\n",
      "Mean Train Loss:0.06678507477045059,escaped time:53.98933744430542\n",
      "Mean Val Loss:0.1953945904970169,Mean IOU:0.7516666666666667, escaped time:1.2486205101013184\n",
      "Mean Train Loss:0.06877050548791885,escaped time:53.994402170181274\n",
      "Mean Val Loss:0.18649621307849884,Mean IOU:0.7497916666666666, escaped time:1.248974323272705\n",
      "Mean Train Loss:0.06522128731012344,escaped time:53.99498462677002\n",
      "Mean Val Loss:0.19757071137428284,Mean IOU:0.7431249999999998, escaped time:1.2499170303344727\n",
      "Mean Train Loss:0.0686265379190445,escaped time:53.997020959854126\n",
      "Mean Val Loss:0.18346504867076874,Mean IOU:0.7483333333333333, escaped time:1.2494335174560547\n",
      "Mean Train Loss:0.06746122986078262,escaped time:53.992942571640015\n",
      "Mean Val Loss:0.18967176973819733,Mean IOU:0.7495833333333335, escaped time:1.2490043640136719\n"
     ]
    }
   ],
   "source": [
    "model=main() # GPU epoch21s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
